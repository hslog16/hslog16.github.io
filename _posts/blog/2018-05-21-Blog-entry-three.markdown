---
layout: post
title:  "Batch Normalization"
date:   2018-05-23 11:51:11
categories: blog
---
We normalize the input layer , For example if we got some features from 0 to 1 and some from 1 to 1000 , we normalize them to speed up learning. If input is getting benefit then we should do it for the values in hidden layers , they usually change all the times and get 10 times or more improvement in training speed.
